{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "INSTALLS AND IMPORTS"
      ],
      "metadata": {
        "id": "tgIYSBRnXYTS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXkxacZC1P1U",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-pinecone pinecone-notebooks\n",
        "!pip install -U langchain\n",
        "!pip install langchain-groq\n",
        "!pip install -qU langchain-huggingface\n",
        "!pip install groq\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "import os\n",
        "import getpass"
      ],
      "metadata": {
        "id": "fAONVfUE4RXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **API KEYS**"
      ],
      "metadata": {
        "id": "UfxyjpObXi0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Login and create the GROQ_API_KEY in https://console.groq.com/keys"
      ],
      "metadata": {
        "id": "rwWAyFxS6mH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = \"YOUR GROQ KEY\"\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"INSERT YOUR GROQ API KEY:\")\n",
        "\n",
        "PINECONE_KEY = \"YOR PINECONE KEY\"\n",
        "pc = Pinecone(api_key=PINECONE_KEY)\n",
        "\n"
      ],
      "metadata": {
        "id": "dpvSiqIr3Brm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CREATE YOUR INDEX AND VECTOR**"
      ],
      "metadata": {
        "id": "k0x2GS9XYl7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = pc.Index(\"YOUR INDEX\")\n",
        "index_name = \"YOUR INDEX NAME\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "index = pc.Index(index_name)\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ],
      "metadata": {
        "id": "8XUHlI3N3kXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SEARCH SIMILARITY IN VECTORS**"
      ],
      "metadata": {
        "id": "Y-PplzfCLblv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_in_db(query):\n",
        "    results = vector_store.similarity_search(\n",
        "        query,\n",
        "        k=4\n",
        "    )\n",
        "    response = []\n",
        "    for res in results:\n",
        "        response.append(f\"* {res.page_content} [{res.metadata}]\")\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "OJagWX1kLInj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DESCRIBE THE PROMPT FROM YOUR TEMPLATE**"
      ],
      "metadata": {
        "id": "kH7flIIRMILk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insert the context in the prompt_template.\n",
        "\n",
        "Example:\n",
        "\n",
        "prompt_template= \"\"\"You are an artificial intelligence model that assists customers.\n",
        "Follow these steps:\n",
        "1) Explore the information about the company found in the PDF.\n",
        "2) Provide a brief and concise answer.\n",
        "3) If the question is not covered in the context, respond with the following phrase: 'I donâ€™t have context to answer your question.\n",
        "Heres the contex :\n",
        "{context} \"\"\""
      ],
      "metadata": {
        "id": "4D9ewacpaQAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "YOU'RE AN EXPERT IN ...\n",
        "Follow the next steps:\n",
        "1 ) INSERT AN STEP.\n",
        "2 ) INSERT AN STEP.\n",
        "3) INSERT AN STEP.\n",
        "Heres the contex :\n",
        "{context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QxN9TAv6MObE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CREATE THE LARGE LANGUAGE MODEL**"
      ],
      "metadata": {
        "id": "Tx8n2THeMZKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    groq_api_key=GROQ_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "nIN3xhWFMfzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"Ask something\")\n",
        "context = search_in_db(query)"
      ],
      "metadata": {
        "id": "hMoBEdN6NSib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            prompt_template,\n",
        "        ),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | llm\n",
        "chain.invoke(\n",
        "    {\n",
        "        \"context\": context,\n",
        "        \"question\": query,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "MxXJgaOfNMgt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}